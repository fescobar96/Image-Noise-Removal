{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Noise Removal.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/fescobar96/Image-Noise-Removal/blob/master/Image_Noise_Removal.ipynb",
      "authorship_tag": "ABX9TyO54ByyPMcZWn1k+KDfAC/2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "789e0ef0dcbb4fb196ce59d95af86ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ed18862bd6924c0cbcc725d8af2fc38b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_35e3495ab41b44cf8ba8a89b4b8f90fe",
              "IPY_MODEL_8dec4405f7b34e6498f5e8cf47ec019c"
            ]
          }
        },
        "ed18862bd6924c0cbcc725d8af2fc38b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35e3495ab41b44cf8ba8a89b4b8f90fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c76d940ba2f4655b3284fdd2a8b214f",
            "_dom_classes": [],
            "description": "  3%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 843,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_acc24b9008fb40ddab1c741a3d7ae574"
          }
        },
        "8dec4405f7b34e6498f5e8cf47ec019c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fa06242cff5b4cb9a2b4101a604772b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26/843 [00:18&lt;07:47,  1.75it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb20331b536a4067ae763148daa4c2e0"
          }
        },
        "9c76d940ba2f4655b3284fdd2a8b214f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "acc24b9008fb40ddab1c741a3d7ae574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa06242cff5b4cb9a2b4101a604772b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb20331b536a4067ae763148daa4c2e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ykviNTsSvZY",
        "colab_type": "text"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMTbRSbNLFSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUEuXuwjSrN2",
        "colab_type": "text"
      },
      "source": [
        "# Noise = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlJtilBjWYDk",
        "colab_type": "text"
      },
      "source": [
        "Import Noisy Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AljKEFWLLy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bad_frames = '/content/drive/My Drive/natural-images/natural_images/noisy_flower/0.1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4zEEp4VSo2I",
        "colab_type": "code",
        "outputId": "a0a78a41-38f9-4682-c837-aa5be1ff2771",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406,
          "referenced_widgets": [
            "789e0ef0dcbb4fb196ce59d95af86ae8",
            "ed18862bd6924c0cbcc725d8af2fc38b",
            "35e3495ab41b44cf8ba8a89b4b8f90fe",
            "8dec4405f7b34e6498f5e8cf47ec019c",
            "9c76d940ba2f4655b3284fdd2a8b214f",
            "acc24b9008fb40ddab1c741a3d7ae574",
            "fa06242cff5b4cb9a2b4101a604772b5",
            "eb20331b536a4067ae763148daa4c2e0"
          ]
        }
      },
      "source": [
        "noisy_frames = []\n",
        "for file in tqdm(sorted(os.listdir(bad_frames))):\n",
        "  if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n",
        "    image = tf.keras.preprocessing.image.load_img(bad_frames + '/' + file, target_size=(420,540))\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32')/255\n",
        "    noisy_frames.append(image)\n",
        "\n",
        "noisy_frames = np.array(noisy_frames)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "789e0ef0dcbb4fb196ce59d95af86ae8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=843), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c800deece0a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_frames\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m420\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m540\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnoisy_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phFM739JS0rV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(noisy_frames.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE0eD5rbWaex",
        "colab_type": "text"
      },
      "source": [
        "Import Clean Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lmJCkCcWI3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "good_frames = '/content/drive/My Drive/natural-images/natural_images/flower'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av_ZvJXJWhw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_frames = []\n",
        "for file in tqdm(sorted(os.listdir(good_frames))):\n",
        "  if any(extension in file for extension in ['.jpg', 'jpeg', '.png']):\n",
        "    image = tf.keras.preprocessing.image.load_img(good_frames + '/' + file, target_size=(420,540))\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image).astype('float32')/255\n",
        "    clean_frames.append(image)\n",
        "\n",
        "clean_frames = np.array(clean_frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJJJ0YmqWqRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(clean_frames.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prh_llLSXat1",
        "colab_type": "text"
      },
      "source": [
        "Split Images Into Training & Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q_v9sUUXkYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "round(len(noisy_frames)*0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8jSsMFRXifG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#80% of images to training set\n",
        "noisy_train = noisy_frames[0:round(len(noisy_frames)*0.8)]\n",
        "noisy_test = noisy_frames[round(len(noisy_frames)*0.8):]\n",
        "\n",
        "clean_train = clean_frames[0:round(len(clean_frames)*0.8)]\n",
        "clean_test = clean_frames[round(len(clean_frames)*0.8):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FshymCrMYgCr",
        "colab_type": "text"
      },
      "source": [
        "Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXJpxv-hZbdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder = tf.keras.models.Sequential([\n",
        "                                          tf.keras.layers.Conv2D(filters = 32, \n",
        "                                                                 kernel_size = (3,3),\n",
        "                                                                 activation = 'relu',\n",
        "                                                                 padding = 'same', \n",
        "                                                                 input_shape = clean_frames.shape[1:4]),\n",
        "                                          tf.keras.layers.Conv2D(filters = 16, \n",
        "                                                                 kernel_size = (3,3),\n",
        "                                                                 activation = 'relu',\n",
        "                                                                 padding = 'same'),\n",
        "                                          tf.keras.layers.Conv2D(filters = 8, \n",
        "                                                                 kernel_size = (3,3),\n",
        "                                                                 activation = 'relu',\n",
        "                                                                 padding = 'same'),\n",
        "                                          tf.keras.layers.Conv2D(filters = 8, \n",
        "                                                                 kernel_size = (3,3),\n",
        "                                                                 activation = 'relu',\n",
        "                                                                 padding = 'same'),\n",
        "                                          tf.keras.layers.Conv2D(filters = 16, \n",
        "                                                                 kernel_size = (3,3),\n",
        "                                                                 activation = 'relu',\n",
        "                                                                 padding = 'same'),\n",
        "                                          tf.keras.layers.Conv2D(filters = 32, \n",
        "                                                                 kernel_size = (3,3),\n",
        "                                                                 activation = 'relu',\n",
        "                                                                 padding = 'same')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II7naiQxaovu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0wZr3Mra2xW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRsuPSjsbEpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = autoencoder.fit(noisy_train, clean_train, epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}